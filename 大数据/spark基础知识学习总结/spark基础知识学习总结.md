# 引言：
    Spark项目包含多个紧密集成的组件，它的核心是一个对由很多计算任务组成的，运行在多个工作机器或者是一个计算集群上的应用进行调度、分发以及监控的计算引擎、由于spark的核心引擎有着速度快和通用的特点，因此spark还支持为各种不同应用场景专门设计的高级组件，这些组件关系密切并且可以相互调用。Spark主要由SparkSQL、sparkStreaming、MLib、GraphX、SparkCore、独立调度器、YARN、Mesos等组件构成sparkcore实现了spark的基本功能，包含了任务调度、内存管理、错误恢复、与存储系统的交互等模块，它还包含了对RDD的API的定义；Sparksql是spark用来操作结构化数据的程序包；sparkStreaming是spark提供的对实时数据进行流式计算的组件；MLlib是机器学习工程程序库；GraphX是操作图的程序库。

# 一、Spark下载与入门
  （1）学习spark环境搭建

  （2）学习独立应用的编写：初始化sparkContext和构建独立应用

# 二、RDD编程
   （1）了解RDD是什么

   （2）了解RDD的操作

   （3）了解为什么RDD对于map-reduce存在优势

   （4）RDD的持久化

# 三、键值对操作
（1）学习创建PairRDD

（2）学习PairRDD几种转化操作：聚合、数据分组、连接、数据排序

（3）数据分区操作

# 四、数据读取与保存
（1）学习它支持的主要几个文件格式，以及文件压缩以增加文件存储效率

（2）HDFS文件系统

（3）相关数据库操作：java数据库连接、HBase、Elasticsearch

# 五、Spark编程进阶
（1）累加器和广播变量

（2）学习与外部程序的管道以及数值RDD的操作

# 六、学习在集群上运行spark
（1）驱动器节点

（2）执行器节点

（3）集群管理器YARN

# 七、spark调优和测试
（1）配置sparkConf

（2）查找信息：通过web界面、驱动器进程日志和执行器进程日志

（3）关键性能考量：并行度、序列化格式、内存管理、硬件情况

# 八、学习SparkSQL
（1）初始化SparkSQL

（2）学习基本使用方法

（3）了解了一下HiveQL

# 九、学习SparkStreaming
（1）两种转化操作：无状态转化和有状态转化

（2）各类数据源：核心数据源、附加数据源、多数据源和集群规模

（3）检查点机制、各类容错机制

（4）影响性能的方面：批次和窗口大小、并行度、垃圾回收和内存使用情况

# 十、学习MLlib相关知识
（1）学习特征提取、统、分类、回归、聚类、降维、协同过滤与推荐

（2）影响性能的各个方面：RDD的缓存和重复使用率、稀疏程度识别、并行度

原文在我的个人小站中，请多多支持：http://www.canfeng.xyz/blog/article?slug=sCIdM90p